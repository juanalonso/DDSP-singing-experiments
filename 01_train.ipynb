{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "01_train",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "LrFAAZbL03cA"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZkLdNoJXmnkk"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NRjan40PzSeb"
      },
      "source": [
        "DRIVE_BASE_DIR = '/SMC 09/DDSP' #@param {type: \"string\"}\n",
        "INSTRUMENT = 'violin' #@param {type: \"string\"}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i_Ph9Y3pZKJD"
      },
      "source": [
        "# Install and import\n",
        "Run this cell to install the DDSP libraries (ignore apache-beam errors), import the Python libraries and check if the notebook is running on a GPU."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HgJ9TmSA2n98"
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "!pip install -qU ddsp[data_preparation]==1.0.1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7W2szb7o-PT8"
      },
      "source": [
        "import os\n",
        "import glob\n",
        "import gin\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "import ddsp.training\n",
        "from ddsp.colab import colab_utils\n",
        "from ddsp.colab.colab_utils import play, specplot\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "%config InlineBackend.figure_format='retina'\n",
        "\n",
        "%reload_ext tensorboard\n",
        "import tensorboard as tb"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "by27WYauyszx"
      },
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Select the Runtime > \"Change runtime type\" menu to enable a GPU accelerator, ')\n",
        "  print('and then re-execute this cell.')\n",
        "else:\n",
        "  print(gpu_info)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9iaML9mQy6e9"
      },
      "source": [
        "def get_frame(fromDataset = True):\n",
        "  data_provider = ddsp.training.data.TFRecordProvider(TRAIN_TFRECORD_FILEPATTERN)\n",
        "  if fromDataset:\n",
        "    dataset = data_provider.get_dataset(shuffle=False)\n",
        "  else:\n",
        "    dataset = data_provider.get_batch(batch_size=1, shuffle=True)\n",
        "\n",
        "  try:\n",
        "    frame = next(iter(dataset))\n",
        "    return frame\n",
        "  except StopIteration:\n",
        "    raise ValueError(\n",
        "        'TFRecord contains no examples. Please try re-running the pipeline with '\n",
        "        'different audio file(s).')\n",
        "  except OutOfRangeError:\n",
        "    raise ValueError(\n",
        "        'TFRecord contains no examples. Please try re-running the pipeline with '\n",
        "        'different audio file(s).')    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tzEIK9H1zWKF"
      },
      "source": [
        "# Define folders\n",
        "Point DRIVE_BASE_DIR to a folder in Google Drive. DRIVE_BASE_DIR should contain a folder called \"audio\". Create a folder inside \"audio\" for each instrument, and put there the mp3 and wav files that will be used to train the model. \n",
        "\n",
        "*For example, to train the model with flute sounds, create DRIVE_BASE_DIR/audio/flute and put there around 15-20 minutes worth of flute sounds. It is better to split the audio files into smaller pieces (2-4 minutes are ok) than having a single 20-minute long audio file.*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nGphz4SPFGC0"
      },
      "source": [
        "DRIVE_BASE_DIR = '/content/drive/My Drive' + DRIVE_BASE_DIR\n",
        "DRIVE_AUDIO_DIR = DRIVE_BASE_DIR + '/audio'\n",
        "assert os.path.exists(DRIVE_AUDIO_DIR + '/' + INSTRUMENT)\n",
        "\n",
        "COLAB_AUDIO_DIR = 'data/' + INSTRUMENT + '_audio' \n",
        "!mkdir -p \"$COLAB_AUDIO_DIR\"\n",
        "AUDIO_FILEPATTERN = COLAB_AUDIO_DIR + '/*'\n",
        "\n",
        "DRIVE_CHECKPOINTS_DIR = os.path.join(DRIVE_AUDIO_DIR, INSTRUMENT+'_checkpoints')\n",
        "!mkdir -p \"$DRIVE_CHECKPOINTS_DIR\"\n",
        "DRIVE_DATASET_DIR = DRIVE_AUDIO_DIR + '/' + INSTRUMENT + '_dataset' \n",
        "\n",
        "COLAB_TRAIN_TFRECORD = 'data/' + INSTRUMENT + '_dataset/train.tfrecord'\n",
        "TRAIN_TFRECORD_FILEPATTERN = COLAB_TRAIN_TFRECORD + '*'\n",
        "\n",
        "!mkdir -p \"$DRIVE_BASE_DIR/instruments/\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2BC_WQjxzsSe"
      },
      "source": [
        "# Prepare dataset\n",
        "If no dataset is present (i.e. folder DRIVE_BASE_DIR/audio/INSTRUMENT_dataset is empty) the audio files are copied to Colab, the dataset is created, and copied back to Drive for safekeeping.\n",
        "\n",
        "If the dataset is present, the dataset files are copied to Colab."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "04UQn0zmjha6"
      },
      "source": [
        "dataset_files = glob.glob(DRIVE_DATASET_DIR + '/*')\n",
        "\n",
        "if len(dataset_files) == 0:  \n",
        "\n",
        "  #Copy audio files\n",
        "  mp3_files = glob.glob(os.path.join(DRIVE_AUDIO_DIR + '/' + INSTRUMENT, '*.mp3'))\n",
        "  wav_files = glob.glob(os.path.join(DRIVE_AUDIO_DIR + '/' + INSTRUMENT, '*.wav'))\n",
        "  audio_files = mp3_files + wav_files\n",
        "  #TODO: remove parenthesis in filenames\n",
        "  for fname in audio_files:\n",
        "    target_name = os.path.join(COLAB_AUDIO_DIR, \n",
        "                               os.path.basename(fname).replace(' ', '_').replace('\\'', '_'))\n",
        "    print('Copying {} to {}'.format(fname, target_name))\n",
        "    !cp \"$fname\" $target_name\n",
        "  \n",
        "\n",
        "  #Create dataset\n",
        "  print(\"Creating \" + INSTRUMENT + \" dataset\")\n",
        "  if not glob.glob(AUDIO_FILEPATTERN):\n",
        "    raise ValueError('No audio files found')\n",
        "  \n",
        "  !ddsp_prepare_tfrecord \\\n",
        "    --input_audio_filepatterns=$AUDIO_FILEPATTERN \\\n",
        "    --output_tfrecord_path=$COLAB_TRAIN_TFRECORD \\\n",
        "    --num_shards=10 \\\n",
        "    --alsologtostderr\n",
        "  \n",
        "\n",
        "  #Copy dataset to drive for safe-keeping.\n",
        "  !mkdir \"$DRIVE_DATASET_DIR\"/\n",
        "  print('Saving to {}'.format(DRIVE_DATASET_DIR))\n",
        "  !cp $TRAIN_TFRECORD_FILEPATTERN \"$DRIVE_DATASET_DIR\"/\n",
        "  \n",
        "  data_provider = ddsp.training.data.TFRecordProvider(TRAIN_TFRECORD_FILEPATTERN)\n",
        "  dataset = data_provider.get_dataset(shuffle=False)\n",
        "  \n",
        "  PICKLE_FILE_PATH = os.path.join(DRIVE_CHECKPOINTS_DIR, 'dataset_statistics.pkl')\n",
        "  colab_utils.save_dataset_statistics(data_provider, PICKLE_FILE_PATH)\n",
        "\n",
        "else:\n",
        "\n",
        "\n",
        "  #Copy the dataset from Drive to Colab\n",
        "  print(\"Restoring dataset for \" + INSTRUMENT)\n",
        "  !mkdir -p 'data/'$INSTRUMENT'_dataset'\n",
        "  !cp \"$DRIVE_DATASET_DIR\"/* 'data/'$INSTRUMENT'_dataset/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LrFAAZbL03cA"
      },
      "source": [
        "# Sanity check 1\n",
        "Choose a frame, plot it, play and show F0, confidence and loudness values.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WrclnFvPq63B"
      },
      "source": [
        "frame = get_frame()\n",
        "\n",
        "colab_utils.specplot(frame['audio'])\n",
        "colab_utils.play(frame['audio'])\n",
        "\n",
        "f, ax = plt.subplots(3, 1, figsize=(12, 8))\n",
        "x = np.linspace(0, 4.0, 1000)\n",
        "ax[0].set_ylabel('loudness_db')\n",
        "ax[0].plot(x, frame['loudness_db'])\n",
        "ax[1].set_ylabel('f0_Hz')\n",
        "ax[1].plot(x, frame['f0_hz'])\n",
        "ax[2].set_ylabel('f0_confidence')\n",
        "ax[2].set_xlabel('seconds')\n",
        "_ = ax[2].plot(x, frame['f0_confidence'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WOC1h3ey1Jma"
      },
      "source": [
        "# Launch TensorBoard"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R-u6D6FDrSsY"
      },
      "source": [
        "tb.notebook.start('--logdir \"{}\"'.format(DRIVE_CHECKPOINTS_DIR))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F-VLCMyO1ZAy"
      },
      "source": [
        "# Train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zvh__dferWPX"
      },
      "source": [
        "#TODO: make an easier way to choose gin file for training\n",
        "\n",
        "!ddsp_run \\\n",
        "  --mode=train \\\n",
        "  --alsologtostderr \\\n",
        "  --save_dir=\"$DRIVE_CHECKPOINTS_DIR\" \\\n",
        "  --gin_file='$DRIVE_AUDIO_DIR/singing_z.gin' \\\n",
        "  --gin_file=datasets/tfrecord.gin \\\n",
        "  --gin_param=\"TFRecordProvider.file_pattern='$TRAIN_TFRECORD_FILEPATTERN'\" \\\n",
        "  --gin_param=\"batch_size=32\" \\\n",
        "  --gin_param=\"train_util.train.num_steps=30000\" \\\n",
        "  --gin_param=\"train_util.train.steps_per_save=250\" \\\n",
        "  --gin_param=\"train_util.train.steps_per_summary=250\" \\\n",
        "  --gin_param=\"trainers.Trainer.checkpoints_to_keep=5\"\n",
        "\n",
        "#  --gin_file='$DRIVE_AUDIO_DIR/singing.gin' \\\n",
        "#  --gin_file='$DRIVE_AUDIO_DIR/singing_z.gin' \\"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ktxbxVqE-esc"
      },
      "source": [
        "# Sanity check 2\n",
        "Resynthesis of a existing frame.\n",
        "\n",
        "*Since the v1.0 update, an error regarding not been able to find the gin file appears from time to time. Just rerun the cell and it will be fine (!)*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UOOqY4DgibLs"
      },
      "source": [
        "batch = get_frame(fromDataset=False)\n",
        "\n",
        "\n",
        "# Parse the gin config.\n",
        "gin_file = os.path.join(DRIVE_CHECKPOINTS_DIR, 'operative_config-0.gin')\n",
        "gin.parse_config_file(gin_file)\n",
        "\n",
        "# Load model\n",
        "model = ddsp.training.models.Autoencoder()\n",
        "model.restore(DRIVE_CHECKPOINTS_DIR)\n",
        "\n",
        "# Original audio\n",
        "audio_orig = batch['audio']\n",
        "\n",
        "# Resynthesized audio\n",
        "outputs = model(batch, training=False)\n",
        "audio_gen = model.get_audio_from_outputs(outputs)\n",
        "\n",
        "print('Original Audio')\n",
        "specplot(audio_orig)\n",
        "play(audio_orig)\n",
        "\n",
        "print('Resynthesis')\n",
        "specplot(audio_gen)\n",
        "play(audio_gen)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GZ3eGs9_-o4U"
      },
      "source": [
        "#Export instrument\n",
        "The model is zipped and copied back to Google Drive."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LLyX8zKUjHR9"
      },
      "source": [
        "CHECKPOINT_ZIP = INSTRUMENT + '_instrument.zip'\n",
        "latest_checkpoint_fname = os.path.basename(tf.train.latest_checkpoint(DRIVE_CHECKPOINTS_DIR))\n",
        "!cd \"$DRIVE_CHECKPOINTS_DIR\" && zip $CHECKPOINT_ZIP $latest_checkpoint_fname* operative_config-0.gin dataset_statistics.pkl\n",
        "!cp \"$DRIVE_CHECKPOINTS_DIR/$CHECKPOINT_ZIP\" \"$DRIVE_BASE_DIR/instruments/\" "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s6-xNT-hEnzA"
      },
      "source": [
        "#Colab clean-up\n",
        "Useful if running out of space in Colab. Be sure to save everything to local before uncommenting and executing: there is no undo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fsXOlePw6cLQ"
      },
      "source": [
        "#!rm -r /content/data\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}